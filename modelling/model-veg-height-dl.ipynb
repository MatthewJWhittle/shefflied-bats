{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/matthewwhittle/Data Science/shefflied-bats\n"
     ]
    }
   ],
   "source": [
    "from sdm.utils import set_project_wd\n",
    "set_project_wd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sdm.models import S2Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2\n",
    "img_transforms = v2.Compose([\n",
    "    # Rotate\n",
    "    v2.RandomRotation(30, expand=True),\n",
    "    # Flip\n",
    "    v2.RandomHorizontalFlip(0.2),\n",
    "    v2.RandomVerticalFlip(0.2),\n",
    "    # Affine\n",
    "    v2.RandomAffine(10, translate=(0.2, 0.2), scale=(0.8, 1.2), shear=0.2),\n",
    "    v2.Resize((304, 304)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = S2Dataset(transforms=img_transforms)\n",
    "n_input_bands = len(dataset.input_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataloader and split into train and validation\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "batch_size = 32\n",
    "validation_split = .2\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=8)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=8)\n",
    "\n",
    "test_dataloader.dataset.dataset.transforms = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 304, 304])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 Batch 1/51 Loss: 4.9289 RMSE: 2.2201\n",
      "Epoch 1/5 Batch 2/51 Loss: 6.0312 RMSE: 2.4559\n",
      "Epoch 1/5 Batch 3/51 Loss: 6.5354 RMSE: 2.5565\n",
      "Epoch 1/5 Batch 4/51 Loss: 3.1967 RMSE: 1.7879\n",
      "Epoch 1/5 Batch 5/51 Loss: 2.0034 RMSE: 1.4154\n",
      "Epoch 1/5 Batch 6/51 Loss: 2.3393 RMSE: 1.5295\n",
      "Epoch 1/5 Batch 7/51 Loss: 1.7347 RMSE: 1.3171\n",
      "Epoch 1/5 Batch 8/51 Loss: 1.8539 RMSE: 1.3616\n",
      "Epoch 1/5 Batch 9/51 Loss: 2.5637 RMSE: 1.6012\n",
      "Epoch 1/5 Batch 10/51 Loss: 1.6212 RMSE: 1.2733\n",
      "Epoch 1/5 Batch 11/51 Loss: 2.1153 RMSE: 1.4544\n",
      "Epoch 1/5 Batch 12/51 Loss: 1.6051 RMSE: 1.2669\n",
      "Epoch 1/5 Batch 13/51 Loss: 1.8478 RMSE: 1.3594\n",
      "Epoch 1/5 Batch 14/51 Loss: 1.4264 RMSE: 1.1943\n",
      "Epoch 1/5 Batch 15/51 Loss: 1.7285 RMSE: 1.3147\n",
      "Epoch 1/5 Batch 16/51 Loss: 2.0081 RMSE: 1.4171\n",
      "Epoch 1/5 Batch 17/51 Loss: 2.3706 RMSE: 1.5397\n",
      "Epoch 1/5 Batch 18/51 Loss: 1.7244 RMSE: 1.3132\n",
      "Epoch 1/5 Batch 19/51 Loss: 1.2063 RMSE: 1.0983\n",
      "Epoch 1/5 Batch 20/51 Loss: 1.5998 RMSE: 1.2648\n",
      "Epoch 1/5 Batch 21/51 Loss: 1.5232 RMSE: 1.2342\n",
      "Epoch 1/5 Batch 22/51 Loss: 1.2645 RMSE: 1.1245\n",
      "Epoch 1/5 Batch 23/51 Loss: 1.7127 RMSE: 1.3087\n",
      "Epoch 1/5 Batch 24/51 Loss: 1.6554 RMSE: 1.2866\n",
      "Epoch 1/5 Batch 25/51 Loss: 1.8470 RMSE: 1.3590\n",
      "Epoch 1/5 Batch 26/51 Loss: 1.0464 RMSE: 1.0229\n",
      "Epoch 1/5 Batch 27/51 Loss: 1.5861 RMSE: 1.2594\n",
      "Epoch 1/5 Batch 28/51 Loss: 2.0918 RMSE: 1.4463\n",
      "Epoch 1/5 Batch 29/51 Loss: 1.4839 RMSE: 1.2182\n",
      "Epoch 1/5 Batch 30/51 Loss: 1.4600 RMSE: 1.2083\n",
      "Epoch 1/5 Batch 31/51 Loss: 1.3896 RMSE: 1.1788\n",
      "Epoch 1/5 Batch 32/51 Loss: 1.4321 RMSE: 1.1967\n",
      "Epoch 1/5 Batch 33/51 Loss: 1.6498 RMSE: 1.2845\n",
      "Epoch 1/5 Batch 34/51 Loss: 1.1654 RMSE: 1.0795\n",
      "Epoch 1/5 Batch 35/51 Loss: 1.1650 RMSE: 1.0794\n",
      "Epoch 1/5 Batch 36/51 Loss: 1.5648 RMSE: 1.2509\n",
      "Epoch 1/5 Batch 37/51 Loss: 1.0291 RMSE: 1.0144\n",
      "Epoch 1/5 Batch 38/51 Loss: 1.0788 RMSE: 1.0386\n",
      "Epoch 1/5 Batch 39/51 Loss: 1.0717 RMSE: 1.0353\n",
      "Epoch 1/5 Batch 40/51 Loss: 1.7885 RMSE: 1.3373\n",
      "Epoch 1/5 Batch 41/51 Loss: 1.0829 RMSE: 1.0406\n",
      "Epoch 1/5 Batch 42/51 Loss: 1.3101 RMSE: 1.1446\n",
      "Epoch 1/5 Batch 43/51 Loss: 1.2182 RMSE: 1.1037\n",
      "Epoch 1/5 Batch 44/51 Loss: 1.0620 RMSE: 1.0306\n",
      "Epoch 1/5 Batch 45/51 Loss: 1.8062 RMSE: 1.3439\n",
      "Epoch 1/5 Batch 46/51 Loss: 0.8980 RMSE: 0.9476\n",
      "Epoch 1/5 Batch 47/51 Loss: 1.4625 RMSE: 1.2093\n",
      "Epoch 1/5 Batch 48/51 Loss: 1.0337 RMSE: 1.0167\n",
      "Epoch 1/5 Batch 49/51 Loss: 1.4531 RMSE: 1.2055\n",
      "Epoch 1/5 Batch 50/51 Loss: 1.1377 RMSE: 1.0666\n",
      "Epoch 1/5 Batch 51/51 Loss: 1.2963 RMSE: 1.1386\n",
      "Epoch 1/5 Loss: 1.8275978097728653 RMSE: 1.3519\n",
      "Epoch 1/5 Validation Loss: 9.742385717538687 RMSE: 3.1213\n",
      "Epoch 2/5 Batch 1/51 Loss: 3.1189 RMSE: 1.7660\n",
      "Epoch 2/5 Batch 2/51 Loss: 1.6108 RMSE: 1.2692\n",
      "Epoch 2/5 Batch 3/51 Loss: 1.4812 RMSE: 1.2170\n",
      "Epoch 2/5 Batch 4/51 Loss: 2.1727 RMSE: 1.4740\n",
      "Epoch 2/5 Batch 5/51 Loss: 1.6181 RMSE: 1.2720\n",
      "Epoch 2/5 Batch 6/51 Loss: 2.0233 RMSE: 1.4224\n",
      "Epoch 2/5 Batch 7/51 Loss: 1.7764 RMSE: 1.3328\n",
      "Epoch 2/5 Batch 8/51 Loss: 1.3784 RMSE: 1.1740\n",
      "Epoch 2/5 Batch 9/51 Loss: 2.2794 RMSE: 1.5098\n",
      "Epoch 2/5 Batch 10/51 Loss: 1.3214 RMSE: 1.1495\n",
      "Epoch 2/5 Batch 11/51 Loss: 1.2886 RMSE: 1.1352\n",
      "Epoch 2/5 Batch 12/51 Loss: 1.6377 RMSE: 1.2797\n",
      "Epoch 2/5 Batch 13/51 Loss: 1.5519 RMSE: 1.2457\n",
      "Epoch 2/5 Batch 14/51 Loss: 1.5398 RMSE: 1.2409\n",
      "Epoch 2/5 Batch 15/51 Loss: 1.4168 RMSE: 1.1903\n",
      "Epoch 2/5 Batch 16/51 Loss: 1.9123 RMSE: 1.3829\n",
      "Epoch 2/5 Batch 17/51 Loss: 1.5463 RMSE: 1.2435\n",
      "Epoch 2/5 Batch 18/51 Loss: 1.4322 RMSE: 1.1968\n",
      "Epoch 2/5 Batch 19/51 Loss: 1.2142 RMSE: 1.1019\n",
      "Epoch 2/5 Batch 20/51 Loss: 1.6019 RMSE: 1.2657\n",
      "Epoch 2/5 Batch 21/51 Loss: 1.3007 RMSE: 1.1405\n",
      "Epoch 2/5 Batch 22/51 Loss: 1.6979 RMSE: 1.3030\n",
      "Epoch 2/5 Batch 23/51 Loss: 1.2743 RMSE: 1.1289\n",
      "Epoch 2/5 Batch 24/51 Loss: 1.3943 RMSE: 1.1808\n",
      "Epoch 2/5 Batch 25/51 Loss: 1.4717 RMSE: 1.2131\n",
      "Epoch 2/5 Batch 26/51 Loss: 1.4062 RMSE: 1.1858\n",
      "Epoch 2/5 Batch 27/51 Loss: 1.1217 RMSE: 1.0591\n",
      "Epoch 2/5 Batch 28/51 Loss: 1.3044 RMSE: 1.1421\n",
      "Epoch 2/5 Batch 29/51 Loss: 1.3754 RMSE: 1.1728\n",
      "Epoch 2/5 Batch 30/51 Loss: 1.4078 RMSE: 1.1865\n",
      "Epoch 2/5 Batch 31/51 Loss: 1.4817 RMSE: 1.2173\n",
      "Epoch 2/5 Batch 32/51 Loss: 1.2316 RMSE: 1.1098\n",
      "Epoch 2/5 Batch 33/51 Loss: 0.9644 RMSE: 0.9821\n",
      "Epoch 2/5 Batch 34/51 Loss: 1.1352 RMSE: 1.0654\n",
      "Epoch 2/5 Batch 35/51 Loss: 1.5248 RMSE: 1.2348\n",
      "Epoch 2/5 Batch 36/51 Loss: 1.6054 RMSE: 1.2670\n",
      "Epoch 2/5 Batch 37/51 Loss: 0.8862 RMSE: 0.9414\n",
      "Epoch 2/5 Batch 38/51 Loss: 1.1509 RMSE: 1.0728\n",
      "Epoch 2/5 Batch 39/51 Loss: 1.1560 RMSE: 1.0752\n",
      "Epoch 2/5 Batch 40/51 Loss: 1.4131 RMSE: 1.1888\n",
      "Epoch 2/5 Batch 41/51 Loss: 1.2812 RMSE: 1.1319\n",
      "Epoch 2/5 Batch 42/51 Loss: 1.4679 RMSE: 1.2116\n",
      "Epoch 2/5 Batch 43/51 Loss: 1.1032 RMSE: 1.0503\n",
      "Epoch 2/5 Batch 44/51 Loss: 0.9494 RMSE: 0.9744\n",
      "Epoch 2/5 Batch 45/51 Loss: 1.1858 RMSE: 1.0889\n",
      "Epoch 2/5 Batch 46/51 Loss: 1.1227 RMSE: 1.0596\n",
      "Epoch 2/5 Batch 47/51 Loss: 1.1099 RMSE: 1.0535\n",
      "Epoch 2/5 Batch 48/51 Loss: 1.2921 RMSE: 1.1367\n",
      "Epoch 2/5 Batch 49/51 Loss: 1.8669 RMSE: 1.3664\n",
      "Epoch 2/5 Batch 50/51 Loss: 1.1037 RMSE: 1.0506\n",
      "Epoch 2/5 Batch 51/51 Loss: 1.2479 RMSE: 1.1171\n",
      "Epoch 2/5 Loss: 1.450128340253643 RMSE: 1.2042\n",
      "Epoch 2/5 Validation Loss: 6.8860365106509285 RMSE: 2.6241\n",
      "Epoch 3/5 Batch 1/51 Loss: 0.8675 RMSE: 0.9314\n",
      "Epoch 3/5 Batch 2/51 Loss: 0.8494 RMSE: 0.9216\n",
      "Epoch 3/5 Batch 3/51 Loss: 0.9842 RMSE: 0.9921\n",
      "Epoch 3/5 Batch 4/51 Loss: 1.2334 RMSE: 1.1106\n",
      "Epoch 3/5 Batch 5/51 Loss: 1.1588 RMSE: 1.0765\n",
      "Epoch 3/5 Batch 6/51 Loss: 0.7144 RMSE: 0.8452\n",
      "Epoch 3/5 Batch 7/51 Loss: 1.0522 RMSE: 1.0257\n",
      "Epoch 3/5 Batch 8/51 Loss: 1.0167 RMSE: 1.0083\n",
      "Epoch 3/5 Batch 9/51 Loss: 0.6694 RMSE: 0.8182\n",
      "Epoch 3/5 Batch 10/51 Loss: 1.2342 RMSE: 1.1110\n",
      "Epoch 3/5 Batch 11/51 Loss: 1.3169 RMSE: 1.1476\n",
      "Epoch 3/5 Batch 12/51 Loss: 1.3848 RMSE: 1.1768\n",
      "Epoch 3/5 Batch 13/51 Loss: 2.0445 RMSE: 1.4298\n",
      "Epoch 3/5 Batch 14/51 Loss: 1.4610 RMSE: 1.2087\n",
      "Epoch 3/5 Batch 15/51 Loss: 1.5701 RMSE: 1.2530\n",
      "Epoch 3/5 Batch 16/51 Loss: 1.3094 RMSE: 1.1443\n",
      "Epoch 3/5 Batch 17/51 Loss: 0.9302 RMSE: 0.9645\n",
      "Epoch 3/5 Batch 18/51 Loss: 1.3206 RMSE: 1.1492\n",
      "Epoch 3/5 Batch 19/51 Loss: 0.9638 RMSE: 0.9817\n",
      "Epoch 3/5 Batch 20/51 Loss: 1.1191 RMSE: 1.0579\n",
      "Epoch 3/5 Batch 21/51 Loss: 1.0352 RMSE: 1.0174\n",
      "Epoch 3/5 Batch 22/51 Loss: 1.3065 RMSE: 1.1430\n",
      "Epoch 3/5 Batch 23/51 Loss: 1.3022 RMSE: 1.1411\n",
      "Epoch 3/5 Batch 24/51 Loss: 1.7000 RMSE: 1.3038\n",
      "Epoch 3/5 Batch 25/51 Loss: 1.4475 RMSE: 1.2031\n",
      "Epoch 3/5 Batch 26/51 Loss: 1.0881 RMSE: 1.0431\n",
      "Epoch 3/5 Batch 27/51 Loss: 1.0316 RMSE: 1.0157\n",
      "Epoch 3/5 Batch 28/51 Loss: 1.5114 RMSE: 1.2294\n",
      "Epoch 3/5 Batch 29/51 Loss: 1.6941 RMSE: 1.3016\n",
      "Epoch 3/5 Batch 30/51 Loss: 0.9528 RMSE: 0.9761\n",
      "Epoch 3/5 Batch 31/51 Loss: 0.8425 RMSE: 0.9179\n",
      "Epoch 3/5 Batch 32/51 Loss: 0.9471 RMSE: 0.9732\n",
      "Epoch 3/5 Batch 33/51 Loss: 1.4074 RMSE: 1.1863\n",
      "Epoch 3/5 Batch 34/51 Loss: 1.1996 RMSE: 1.0953\n",
      "Epoch 3/5 Batch 35/51 Loss: 1.0321 RMSE: 1.0159\n",
      "Epoch 3/5 Batch 36/51 Loss: 1.1014 RMSE: 1.0495\n",
      "Epoch 3/5 Batch 37/51 Loss: 1.1749 RMSE: 1.0839\n",
      "Epoch 3/5 Batch 38/51 Loss: 0.9751 RMSE: 0.9875\n",
      "Epoch 3/5 Batch 39/51 Loss: 1.1433 RMSE: 1.0693\n",
      "Epoch 3/5 Batch 40/51 Loss: 0.9446 RMSE: 0.9719\n",
      "Epoch 3/5 Batch 41/51 Loss: 1.3447 RMSE: 1.1596\n",
      "Epoch 3/5 Batch 42/51 Loss: 0.9225 RMSE: 0.9605\n",
      "Epoch 3/5 Batch 43/51 Loss: 1.0765 RMSE: 1.0376\n",
      "Epoch 3/5 Batch 44/51 Loss: 1.1175 RMSE: 1.0571\n",
      "Epoch 3/5 Batch 45/51 Loss: 0.7477 RMSE: 0.8647\n",
      "Epoch 3/5 Batch 46/51 Loss: 1.0300 RMSE: 1.0149\n",
      "Epoch 3/5 Batch 47/51 Loss: 0.8060 RMSE: 0.8978\n",
      "Epoch 3/5 Batch 48/51 Loss: 1.0199 RMSE: 1.0099\n",
      "Epoch 3/5 Batch 49/51 Loss: 1.0542 RMSE: 1.0267\n",
      "Epoch 3/5 Batch 50/51 Loss: 1.3223 RMSE: 1.1499\n",
      "Epoch 3/5 Batch 51/51 Loss: 0.9524 RMSE: 0.9759\n",
      "Epoch 3/5 Loss: 1.1457136518814985 RMSE: 1.0704\n",
      "Epoch 3/5 Validation Loss: 5.538929572472205 RMSE: 2.3535\n",
      "Epoch 4/5 Batch 1/51 Loss: 0.8317 RMSE: 0.9120\n",
      "Epoch 4/5 Batch 2/51 Loss: 0.7648 RMSE: 0.8745\n",
      "Epoch 4/5 Batch 3/51 Loss: 1.3077 RMSE: 1.1436\n",
      "Epoch 4/5 Batch 4/51 Loss: 0.8343 RMSE: 0.9134\n",
      "Epoch 4/5 Batch 5/51 Loss: 0.9064 RMSE: 0.9521\n",
      "Epoch 4/5 Batch 6/51 Loss: 0.6943 RMSE: 0.8333\n",
      "Epoch 4/5 Batch 7/51 Loss: 1.1293 RMSE: 1.0627\n",
      "Epoch 4/5 Batch 8/51 Loss: 0.9289 RMSE: 0.9638\n",
      "Epoch 4/5 Batch 9/51 Loss: 0.9267 RMSE: 0.9626\n",
      "Epoch 4/5 Batch 10/51 Loss: 1.0582 RMSE: 1.0287\n",
      "Epoch 4/5 Batch 11/51 Loss: 1.7823 RMSE: 1.3350\n",
      "Epoch 4/5 Batch 12/51 Loss: 1.3001 RMSE: 1.1402\n",
      "Epoch 4/5 Batch 13/51 Loss: 1.0289 RMSE: 1.0143\n",
      "Epoch 4/5 Batch 14/51 Loss: 1.0572 RMSE: 1.0282\n",
      "Epoch 4/5 Batch 15/51 Loss: 0.8293 RMSE: 0.9106\n",
      "Epoch 4/5 Batch 16/51 Loss: 0.9064 RMSE: 0.9520\n",
      "Epoch 4/5 Batch 17/51 Loss: 1.0011 RMSE: 1.0005\n",
      "Epoch 4/5 Batch 18/51 Loss: 1.0088 RMSE: 1.0044\n",
      "Epoch 4/5 Batch 19/51 Loss: 1.0932 RMSE: 1.0456\n",
      "Epoch 4/5 Batch 20/51 Loss: 0.7865 RMSE: 0.8868\n",
      "Epoch 4/5 Batch 21/51 Loss: 1.6342 RMSE: 1.2784\n",
      "Epoch 4/5 Batch 22/51 Loss: 1.0297 RMSE: 1.0148\n",
      "Epoch 4/5 Batch 23/51 Loss: 1.3041 RMSE: 1.1420\n",
      "Epoch 4/5 Batch 24/51 Loss: 1.2921 RMSE: 1.1367\n",
      "Epoch 4/5 Batch 25/51 Loss: 0.9966 RMSE: 0.9983\n",
      "Epoch 4/5 Batch 26/51 Loss: 0.8242 RMSE: 0.9079\n",
      "Epoch 4/5 Batch 27/51 Loss: 1.2680 RMSE: 1.1260\n",
      "Epoch 4/5 Batch 28/51 Loss: 0.6605 RMSE: 0.8127\n",
      "Epoch 4/5 Batch 29/51 Loss: 1.3245 RMSE: 1.1509\n",
      "Epoch 4/5 Batch 30/51 Loss: 0.9460 RMSE: 0.9726\n",
      "Epoch 4/5 Batch 31/51 Loss: 1.2002 RMSE: 1.0955\n",
      "Epoch 4/5 Batch 32/51 Loss: 1.0851 RMSE: 1.0417\n",
      "Epoch 4/5 Batch 33/51 Loss: 1.1319 RMSE: 1.0639\n",
      "Epoch 4/5 Batch 34/51 Loss: 0.8991 RMSE: 0.9482\n",
      "Epoch 4/5 Batch 35/51 Loss: 1.1119 RMSE: 1.0545\n",
      "Epoch 4/5 Batch 36/51 Loss: 1.3151 RMSE: 1.1468\n",
      "Epoch 4/5 Batch 37/51 Loss: 0.9229 RMSE: 0.9607\n",
      "Epoch 4/5 Batch 38/51 Loss: 1.1477 RMSE: 1.0713\n",
      "Epoch 4/5 Batch 39/51 Loss: 0.9570 RMSE: 0.9782\n",
      "Epoch 4/5 Batch 40/51 Loss: 0.8114 RMSE: 0.9008\n",
      "Epoch 4/5 Batch 41/51 Loss: 1.1192 RMSE: 1.0579\n",
      "Epoch 4/5 Batch 42/51 Loss: 0.9321 RMSE: 0.9655\n",
      "Epoch 4/5 Batch 43/51 Loss: 0.6732 RMSE: 0.8205\n",
      "Epoch 4/5 Batch 44/51 Loss: 0.9128 RMSE: 0.9554\n",
      "Epoch 4/5 Batch 45/51 Loss: 0.8810 RMSE: 0.9386\n",
      "Epoch 4/5 Batch 46/51 Loss: 1.0519 RMSE: 1.0256\n",
      "Epoch 4/5 Batch 47/51 Loss: 1.2949 RMSE: 1.1380\n",
      "Epoch 4/5 Batch 48/51 Loss: 1.1186 RMSE: 1.0576\n",
      "Epoch 4/5 Batch 49/51 Loss: 0.9293 RMSE: 0.9640\n",
      "Epoch 4/5 Batch 50/51 Loss: 0.6320 RMSE: 0.7950\n",
      "Epoch 4/5 Batch 51/51 Loss: 0.8360 RMSE: 0.9143\n",
      "Epoch 4/5 Loss: 1.027828296025594 RMSE: 1.0138\n",
      "Epoch 4/5 Validation Loss: 5.000936448574066 RMSE: 2.2363\n",
      "Epoch 5/5 Batch 1/51 Loss: 0.8075 RMSE: 0.8986\n",
      "Epoch 5/5 Batch 2/51 Loss: 1.2717 RMSE: 1.1277\n",
      "Epoch 5/5 Batch 3/51 Loss: 0.8981 RMSE: 0.9477\n",
      "Epoch 5/5 Batch 4/51 Loss: 1.0759 RMSE: 1.0373\n",
      "Epoch 5/5 Batch 5/51 Loss: 0.9777 RMSE: 0.9888\n",
      "Epoch 5/5 Batch 6/51 Loss: 1.3701 RMSE: 1.1705\n",
      "Epoch 5/5 Batch 7/51 Loss: 0.7969 RMSE: 0.8927\n",
      "Epoch 5/5 Batch 8/51 Loss: 0.6859 RMSE: 0.8282\n",
      "Epoch 5/5 Batch 9/51 Loss: 0.7097 RMSE: 0.8425\n",
      "Epoch 5/5 Batch 10/51 Loss: 0.7265 RMSE: 0.8523\n",
      "Epoch 5/5 Batch 11/51 Loss: 1.2883 RMSE: 1.1350\n",
      "Epoch 5/5 Batch 12/51 Loss: 0.7534 RMSE: 0.8680\n",
      "Epoch 5/5 Batch 13/51 Loss: 1.0972 RMSE: 1.0475\n",
      "Epoch 5/5 Batch 14/51 Loss: 0.8816 RMSE: 0.9389\n",
      "Epoch 5/5 Batch 15/51 Loss: 0.7740 RMSE: 0.8798\n",
      "Epoch 5/5 Batch 16/51 Loss: 0.8890 RMSE: 0.9428\n",
      "Epoch 5/5 Batch 17/51 Loss: 0.7376 RMSE: 0.8588\n",
      "Epoch 5/5 Batch 18/51 Loss: 0.9034 RMSE: 0.9505\n",
      "Epoch 5/5 Batch 19/51 Loss: 1.0007 RMSE: 1.0003\n",
      "Epoch 5/5 Batch 20/51 Loss: 0.6979 RMSE: 0.8354\n",
      "Epoch 5/5 Batch 21/51 Loss: 1.1330 RMSE: 1.0644\n",
      "Epoch 5/5 Batch 22/51 Loss: 1.0156 RMSE: 1.0078\n",
      "Epoch 5/5 Batch 23/51 Loss: 0.9967 RMSE: 0.9983\n",
      "Epoch 5/5 Batch 24/51 Loss: 1.1242 RMSE: 1.0603\n",
      "Epoch 5/5 Batch 25/51 Loss: 0.7203 RMSE: 0.8487\n",
      "Epoch 5/5 Batch 26/51 Loss: 1.0250 RMSE: 1.0124\n",
      "Epoch 5/5 Batch 27/51 Loss: 0.9385 RMSE: 0.9687\n",
      "Epoch 5/5 Batch 28/51 Loss: 1.2800 RMSE: 1.1314\n",
      "Epoch 5/5 Batch 29/51 Loss: 0.8632 RMSE: 0.9291\n",
      "Epoch 5/5 Batch 30/51 Loss: 0.8910 RMSE: 0.9439\n",
      "Epoch 5/5 Batch 31/51 Loss: 1.0346 RMSE: 1.0171\n",
      "Epoch 5/5 Batch 32/51 Loss: 0.8972 RMSE: 0.9472\n",
      "Epoch 5/5 Batch 33/51 Loss: 1.0577 RMSE: 1.0285\n",
      "Epoch 5/5 Batch 34/51 Loss: 1.3666 RMSE: 1.1690\n",
      "Epoch 5/5 Batch 35/51 Loss: 0.4758 RMSE: 0.6898\n",
      "Epoch 5/5 Batch 36/51 Loss: 0.9307 RMSE: 0.9647\n",
      "Epoch 5/5 Batch 37/51 Loss: 1.0425 RMSE: 1.0210\n",
      "Epoch 5/5 Batch 38/51 Loss: 0.6999 RMSE: 0.8366\n",
      "Epoch 5/5 Batch 39/51 Loss: 0.8809 RMSE: 0.9386\n",
      "Epoch 5/5 Batch 40/51 Loss: 1.1428 RMSE: 1.0690\n",
      "Epoch 5/5 Batch 41/51 Loss: 1.0141 RMSE: 1.0070\n",
      "Epoch 5/5 Batch 42/51 Loss: 1.1998 RMSE: 1.0954\n",
      "Epoch 5/5 Batch 43/51 Loss: 1.1578 RMSE: 1.0760\n",
      "Epoch 5/5 Batch 44/51 Loss: 1.0432 RMSE: 1.0214\n",
      "Epoch 5/5 Batch 45/51 Loss: 0.7566 RMSE: 0.8698\n",
      "Epoch 5/5 Batch 46/51 Loss: 0.6711 RMSE: 0.8192\n",
      "Epoch 5/5 Batch 47/51 Loss: 0.7190 RMSE: 0.8479\n",
      "Epoch 5/5 Batch 48/51 Loss: 1.6042 RMSE: 1.2666\n",
      "Epoch 5/5 Batch 49/51 Loss: 0.9623 RMSE: 0.9810\n",
      "Epoch 5/5 Batch 50/51 Loss: 0.7484 RMSE: 0.8651\n",
      "Epoch 5/5 Batch 51/51 Loss: 1.1805 RMSE: 1.0865\n",
      "Epoch 5/5 Loss: 0.9591416471144733 RMSE: 0.9794\n",
      "Epoch 5/5 Validation Loss: 4.6780441999435425 RMSE: 2.1629\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#Â set mac m1 device\n",
    "device = torch.device('mps')\n",
    "\n",
    "# Define the CNN model\n",
    "# TODO: Add dropout\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Vegetation Height Prediction CNN\n",
    "\n",
    "    The model architectures uses a simple CNN with 3 convolutional layers and a gated skip connection.\n",
    "    The gated skip connection is used to allow the model to use values from the original input to predict the output ina flexible way combining them with the higher dimensional features learned by the CNN.\n",
    "    The logic behind this is that the CNN can focus on learning whether something is vegetation or not and the skip connection provides information from the canopy height model to help predict the vegetation height.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input channels (number of bands)\n",
    "        tile_size (int): Size of the input tile. Defaults to 304.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, tile_size=304):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1)  # output 1 channel\n",
    "\n",
    "        # Match the number of output channels with the input for skip connection\n",
    "        self.match_dim = nn.Conv2d(in_channels, 1, kernel_size=1)  # 1x1 convolution\n",
    "        \n",
    "        # For the gating mechanism\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        original_x = x\n",
    "        x = self.bn1(nn.functional.relu(self.conv1(x)))\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        # Match the dimensions\n",
    "        original_x_matched = self.match_dim(original_x)\n",
    "        \n",
    "        # Get the gating values from the original input\n",
    "        gate_values = self.gate(original_x)\n",
    "        \n",
    "        x = x + gate_values * original_x_matched  # element-wise multiplication followed by addition\n",
    "\n",
    "        return x.squeeze(1)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the model, loss, and optimizer\n",
    "model = SimpleCNN(n_input_bands)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression task\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "loss_results = []\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "n_epochs = 5  # Number of epochs\n",
    "early_stop = 3  # Stop if the validation loss does not improve after 5 epochs\n",
    "best_val_loss = 1e10  # Set initial best validation loss to infinity\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    epoch_loss = 0\n",
    "    for i, (inputs, target, idxs) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"Epoch {epoch}/{n_epochs} Batch {i+1}/{len(train_dataloader)} Loss: {loss.item():.4f} RMSE: {loss.item()**0.5:.4f}\")\n",
    "    avg_loss_train = epoch_loss/len(train_dataloader)\n",
    "    print(f\"Epoch {epoch}/{n_epochs} Loss: {avg_loss_train} RMSE: {avg_loss_train**0.5:.4f}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, target, idxs) in enumerate(test_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, target)\n",
    "            epoch_loss += loss.item()\n",
    "        avg_loss_val = epoch_loss/len(test_dataloader)\n",
    "        \n",
    "        print(f\"Epoch {epoch}/{n_epochs} Validation Loss: {avg_loss_val} RMSE: {avg_loss_val**0.5:.4f}\")\n",
    "    \n",
    "    loss_results.append({'train': avg_loss_train, 'val': avg_loss_val})\n",
    "    scheduler.step()\n",
    "    # Early stopping\n",
    "    if avg_loss_val < best_val_loss:\n",
    "        best_val_loss = avg_loss_val\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == early_stop:\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "\n",
    "# Save the model\n",
    "# torch.save(model.state_dict(), \"simple_cnn_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "loss_df =  pd.DataFrame(loss_results)\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdm.models import SpatialTransformer, plot_predictions\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Make some predictions and plot the mask and the prediction in sub plots\n",
    "arrays = []\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, target, idxs) in enumerate(test_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        target_np = target.cpu().numpy()\n",
    "        prediction_np = outputs.cpu().numpy()\n",
    "\n",
    "        # iterate over the batch\n",
    "        for i in range(len(target_np)):\n",
    "            arrays.append({\"target\": target_np[i], \"prediction\": prediction_np[i]})\n",
    "        \n",
    "\n",
    "for i in range(5):\n",
    "    plot_predictions(arrays[i][\"target\"], arrays[i][\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"models/veg-height-cnn.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
